{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HDnlnK_zIns",
    "outputId": "1991fb1e-9f15-4484-e7ad-75b9b5566cfa"
   },
   "outputs": [],
   "source": [
    "# Installing required libraries\n",
    "! pip install sklearn\n",
    "! pip install pandas\n",
    "! pip install sweetviz\n",
    "! pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "spSmHU_OyX6z"
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import sweetviz as sv\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "import imblearn\n",
    "from sklearn import preprocessing\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bLw1bOrxycWW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Fetch the data\n",
    "data_train = pd.read_csv('Train.csv', sep=',',header=0)\n",
    "data_eval = pd.read_csv('Eval.csv', sep=',',header=0)\n",
    "data_train.dropna(how='all',inplace=True)\n",
    "data_train = data_train[(np.abs(stats.zscore(data_train)) < 5).all(axis=1)]\n",
    "feat =  data_train.iloc[:,:-1]\n",
    "label = data_train['class_col']\n",
    "print(pd.unique(label)) # Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.85893870e-01, -2.17003331e-01,  7.16110992e-01, ...,\n",
       "         0.00000000e+00,  2.38703664e-01,  4.77407328e-01],\n",
       "       [-1.66506942e-02,  8.52122884e-01,  0.00000000e+00, ...,\n",
       "        -2.84040961e-01,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 7.58127547e-01,  1.07798948e-01,  0.00000000e+00, ...,\n",
       "        -2.37157685e-01,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 3.92478379e-02,  8.42800248e-02,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  9.27080272e-01],\n",
       "       [ 2.00566653e-05, -1.14022133e-03,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 8.48889598e-02,  2.20756232e-01,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalization\n",
    "min_max_scaler = preprocessing.Normalizer()\n",
    "x_scaled = min_max_scaler.fit_transform(feat.values)\n",
    "\n",
    "x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_scaled, label,test_size =0.30,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step was to do under-sampling to balance the training data to have better representation of both the classes, the technique I am using is condensed nearest neighbours, unfortunately due to the lack of computing power I was not able to complete the test for this run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # define the undersampling method\n",
    "# undersample = CondensedNearestNeighbour(n_neighbors=1)\n",
    "# # transform the dataset\n",
    "# X_train, y_train = undersample.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a04b17640d44fcabf8d6350875ecc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report eda_report_norm_sklearn.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "feature = pd.DataFrame(x_scaled)\n",
    "\n",
    "# EDA of the training file\n",
    "eda_report = sv.analyze(feature)\n",
    "\n",
    "# Saving results to HTML file\n",
    "eda_report.show_html('eda_report_norm_sklearn.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN model accuracy(in %): 93.47672184202543\n",
      "KNN model accuracy(in %): 19.07151819322459\n"
     ]
    }
   ],
   "source": [
    "# KNN-classification\n",
    "KNN = KNeighborsClassifier(n_neighbors=10).fit(X_train, y_train)\n",
    "\n",
    "KNN_pred = KNN.predict(X_test)\n",
    "print(\"KNN model accuracy(in %):\",metrics.accuracy_score(y_test, KNN_pred)*100)\n",
    "print(\"KNN model f1-score(in %):\",metrics.f1_score(y_test, KNN_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes model accuracy(in %): 90.13923069143377\n",
      "Gaussian Naive Bayes model f1-score(in %): 35.75664397100813\n"
     ]
    }
   ],
   "source": [
    "# NaiveBayes Classification\n",
    "gnb = GaussianNB().fit(X_train, y_train) \n",
    "gnb_pred = gnb.predict(X_test)\n",
    "print(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_test, gnb_pred)*100)\n",
    "print(\"Gaussian Naive Bayes model f1-score(in %):\",metrics.f1_score(y_test, gnb_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "6_SvpV2FyfG3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR model accuracy(in %): 93.65202440751104\n",
      "LR  model f1-score(in %): 18.094823836450633\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X_train, y_train)\n",
    "LR_pred = LR.predict(X_test)\n",
    "print(\"LR model accuracy(in %):\",metrics.accuracy_score(y_test, LR_pred)*100)\n",
    "print(\"LR  model f1-score(in %):\",metrics.f1_score(y_test, LR_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fC7ukPHFyhr5"
   },
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "# SVM = svm.LinearSVC().fit(X_train, y_train)\n",
    "SVM = svm.SVC(probability=True).fit(X_train, y_train)\n",
    "SVM_pred = SVM.predict(X_test)\n",
    "print(\"SVM model accuracy(in %):\",metrics.accuracy_score(y_test, SVM_pred)*100)\n",
    "print(\"SVM model f1-score(in %):\",metrics.f1_score(y_test, SVM_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "bLHZBxM9yl2S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model accuracy(in %): 93.6250547820517\n",
      "MLP model f1-score(in %): 21.37214137214137\n"
     ]
    }
   ],
   "source": [
    "#Multi-Layer Perceptron\n",
    "NN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1).fit(X_train, y_train)\n",
    "NN_pred = NN.predict(X_test)\n",
    "print(\"MLP model accuracy(in %):\",metrics.accuracy_score(y_test, NN_pred)*100)\n",
    "print(\"MLP model f1-score(in %):\",metrics.f1_score(y_test, NN_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "GNB_prob = gnb.predict_proba(data_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = list(GNB_prob[:,-1])\n",
    "class1_prob = [round(x,3) for x in prob]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(columns=['row_id', 'yhat'])\n",
    "output['yhat'] = class1_prob\n",
    "output['row_id'] = [x for x in range(len(class1_prob))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sapient_CR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
